{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO needs annotations in format such as like this,  \n",
    "\n",
    "path/to/img1.jpg 50,100,150,200,0 30,50,200,120,3  \n",
    "path/to/img2.jpg 120,300,250,600,2  \n",
    "...  \n",
    "\n",
    "where,  \n",
    "Row format: image_file_path box1 box2 ... boxN  \n",
    "Box format: x_min,y_min,x_max,y_max,class_id (no space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first get unique frames\n",
    "unique_frames = original_data.Frame.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9218,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_frames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data (object-detection-crowdai), we have 3 classes.  \n",
    "labels = {car, truck, pedestrian}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, open a \"yolo_annotations.txt\"\n",
    "\n",
    "file = open('yolo_annotations.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data location\n",
    "image_location = 'object-detection-crowdai/'\n",
    "\n",
    "# extract information per frame\n",
    "for frame in unique_frames:\n",
    "    frame_info = original_data.loc[original_data.Frame == frame]\n",
    "    frame_array = np.asarray(frame_info)\n",
    "    \n",
    "    row = ''\n",
    "    row += image_location\n",
    "    for info in range(frame_array.shape[0]):\n",
    "        # first, get the frame.jpg\n",
    "        if(info == 0):\n",
    "            frame = frame_array[info][4]\n",
    "            row += str(frame) + ' '\n",
    "            \n",
    "        x_min = frame_array[info][0]\n",
    "        y_min = frame_array[info][1]\n",
    "        x_max = frame_array[info][2]\n",
    "        y_max = frame_array[info][3]\n",
    "        \n",
    "        label = frame_array[info][5]\n",
    "        if(label == 'Car'):\n",
    "            label_int = 0\n",
    "        elif(label == 'Truck'):\n",
    "            label_int = 1\n",
    "        elif(label == 'Pedestrian'):\n",
    "            label_int = 2\n",
    "        else:\n",
    "            label_int = -1\n",
    "        \n",
    "        row += str(x_min) + ',' + str(y_min) + ',' + str(x_max) + ',' + str(y_max) + ',' + str(label_int) + ' '\n",
    "    \n",
    "    # just getting ride of the last space (' ') at the end of the row\n",
    "    row = row[:len(row)-1]\n",
    "    \n",
    "    # save this row into the yolo_annotation.txt\n",
    "    file.write(row)\n",
    "    file.write('\\n')\n",
    "    \n",
    "# safely closing the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the labels in YOLO format has been stored as 'yolo_annotation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
